{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# version 5 use truncated_normal\n",
    "#\n",
    "\n",
    "# use mongodb\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://atkePrf0ht5f:yJba03gbpVQh@db2.favorr.io/favorrdb?ssl=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = client.get_default_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get data as dictionary\n",
    "list_1 = list(db.favorr_dl_2.find({'rand':{'$in':[2,3,4]}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use numpay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert data into list \n",
    "list_2 = []\n",
    "\n",
    "for item in list_1:\n",
    "    \n",
    "    # init param\n",
    "    diff_first_timestamp_to_review_wrote = -1\n",
    "    diff_last_and_first_timestamp = -1\n",
    "    clickedAt_exist = 0\n",
    "    sendlinkAt_exist = 0\n",
    "    visitappstoreAt_exist = 0\n",
    "    # target_review_detected = 0\n",
    "    \n",
    "    # get param\n",
    "    view_in_hour = item['view_in_hour']\n",
    "    click_in_hour = item['click_in_hour']\n",
    "    sendlink_in_hour = item['sendlink_in_hour']\n",
    "    appstore_in_hour = item['appstore_in_hour']\n",
    "    session_in_hour = item['session_in_hour']\n",
    "    \n",
    "    view_in_day = item['view_in_day']\n",
    "    click_in_day = item['click_in_day']\n",
    "    sendlink_in_day = item['sendlink_in_day']\n",
    "    appstore_in_day = item['appstore_in_day']\n",
    "    session_in_day = item['session_in_day']\n",
    "\n",
    "    view_in_month = item['view_in_month']\n",
    "    click_in_month = item['click_in_month']\n",
    "    sendlink_in_month = item['sendlink_in_month']\n",
    "    appstore_in_month = item['appstore_in_month']\n",
    "    session_in_month = item['session_in_month']\n",
    "    \n",
    "    session_longest = item['session_longest']\n",
    "    view2review_abs_smallest = item['view2review_abs_smallest']\n",
    "    review_detected = item['review_detected']\n",
    "    review_not_detected = item['review_not_detected']\n",
    "    \n",
    "    \n",
    "    list_2.append([\n",
    "        view_in_hour,\n",
    "        click_in_hour,\n",
    "        sendlink_in_hour,\n",
    "        appstore_in_hour,\n",
    "        view_in_day,\n",
    "        click_in_day,\n",
    "        sendlink_in_day,\n",
    "        appstore_in_day,\n",
    "        view_in_month,\n",
    "        click_in_month,\n",
    "        sendlink_in_month,\n",
    "        appstore_in_month,\n",
    "        session_longest,\n",
    "        view2review_abs_smallest,\n",
    "        review_detected,\n",
    "        review_not_detected\n",
    "        ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1227502, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 80, 785620, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 69972, 1650427, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2389167, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 8118, 2289455, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2214, 2286814, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 5318, 1494619, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1150387, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 16574, 2091606, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 154, 2230627, 0, 1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check list\n",
    "list_2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert list into numpy.array\n",
    "np_list_1 = np.array(list_2, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77590, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "np_list_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we shuffled the dataset\n",
    "np.random.shuffle(np_list_1)\n",
    "np.random.shuffle(np_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   3.45920000e+04,   3.09450000e+04],\n",
       "       [  0.00000000e+00,   1.46790000e+04,   5.07000000e+02],\n",
       "       [  0.00000000e+00,   5.32000000e+02,   9.05250000e+04],\n",
       "       [  0.00000000e+00,   4.28700000e+03,   2.23269600e+06],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   8.47530000e+04]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if shuffled \n",
    "np_list_1[:5, 11:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77590\n"
     ]
    }
   ],
   "source": [
    "# check row count\n",
    "row_count, _ =  np_list_1.shape\n",
    "print(row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.45920000e+04,   3.09450000e+04,   1.00000000e+00,\n",
       "         0.00000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just check\n",
    "np_list_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important: mean_12:6510.951171875, mean_13\n",
      "Important: std_12:37051.27734375, std_13:776581.75\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(np_list_1, axis=0)\n",
    "# print(mean)\n",
    "print(\"Important: mean_12:{}, mean_13:{}\".format(mean[12], mean[13]))\n",
    "std = np.std(np_list_1, axis=0)\n",
    "# print(std)\n",
    "print(\"Important: std_12:{}, std_13:{}\".format(std[12], std[13]))\n",
    "\n",
    "for i in range(3):\n",
    "    np_list_1[i][12] = (np_list_1[i][12] - mean[12])/std[12]\n",
    "    np_list_1[i][13] = (np_list_1[i][13] - mean[13])/std[13]\n",
    "\n",
    "#     print(\"{}, {}, {}\".format(np_list_1[i][16], mean[16], std[16]))\n",
    "    \n",
    "#     aaa = np_list_1[i][16] - mean[16]\n",
    "#     print(\"aaa:{}\".format(aaa))\n",
    "    \n",
    "#     bbb = aaa / std[16]\n",
    "#     print(\"bbb:{}\".format(bbb))\n",
    "#     np_list_1[i][16] =  bbb\n",
    "#     # np_list_1[i][16] =  float(( float(np_list_1[i][16] - mean[16])) /std[16])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  1.41202378, -1.0593853 ,  1.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data again\n",
    "np_list_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split dataset into training, validation, and test\n",
    "\n",
    "traning_validation_data =  np_list_1[:-7000]\n",
    "test_data = np_list_1[-7000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.41202378, -1.0593853 ,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.15440671, -1.11517465,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.17572862, -1.00368595,  0.        ,\n",
       "         1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traning_validation_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   4.80104000e+05,   0.00000000e+00,\n",
       "          1.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.48388000e+05,   0.00000000e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.52600000e+03,   3.37400000e+03,   0.00000000e+00,\n",
       "          1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70590, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traning_validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = traning_validation_data[:-7000]\n",
    "validation_data = traning_validation_data[-7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63590, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = training_data[:,0:14]\n",
    "train_labels = training_data[:,14:]\n",
    "\n",
    "valid_features = validation_data[:,0:14]\n",
    "valid_labels = validation_data[:,14:]\n",
    "\n",
    "test_features = test_data[:,0:14]\n",
    "test_labels = test_data[:,14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# lets do tensorflow things...\n",
    "\n",
    "# the number of hidden layers is 2\n",
    "\n",
    "# number of features and lables\n",
    "features_count = 14\n",
    "labels_count = 2\n",
    "\n",
    "# feature ad labesls\n",
    "features = tf.placeholder(tf.float32, [None, features_count], name=\"x\")\n",
    "labels = tf.placeholder(tf.float32, [None, labels_count], name=\"y\")\n",
    "\n",
    "# Set the weights and biases tensors\n",
    "layer_1_count = 8\n",
    "layer_2_count = 6\n",
    "\n",
    "# USE truncated_normal! this is important!!!\n",
    "\n",
    "weights_1 = tf.Variable(tf.truncated_normal([features_count,\n",
    "                                             layer_1_count],\n",
    "                                             mean=0.0,\n",
    "                                             stddev=0.1), name='weights_1')\n",
    "biases_1 = tf.Variable(tf.truncated_normal([layer_1_count],\n",
    "                                           mean=0.0,\n",
    "                                           stddev=0.1), name='biases_1')\n",
    "\n",
    "weights_2 = tf.Variable(tf.truncated_normal([layer_1_count,\n",
    "                                             layer_2_count],\n",
    "                                             mean=0.0,\n",
    "                                             stddev=0.1), name='weights_2')\n",
    "biases_2 = tf.Variable(tf.truncated_normal([layer_2_count],\n",
    "                                           mean=0.0,\n",
    "                                           stddev=0.1), name='biases_2')\n",
    "\n",
    "\n",
    "weights_3 = tf.Variable(tf.truncated_normal([layer_2_count,\n",
    "                                             labels_count],\n",
    "                                             mean=0.0,\n",
    "                                             stddev=0.1), name='weights_3')\n",
    "biases_3 = tf.Variable(tf.truncated_normal([labels_count],\n",
    "                                           mean=0.0,\n",
    "                                           stddev=0.1), name='biases_3')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features, labels: train_labels, keep_prob:0.75}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels, keep_prob:0.75}\n",
    "test_feed_dict = {features: test_features, labels: test_labels, keep_prob:0.75}\n",
    "\n",
    "# tensorflow gragh\n",
    "\n",
    "# layer 1\n",
    "output_1 = tf.add(tf.matmul(features, weights_1) , biases_1)\n",
    "output_1 = tf.nn.relu(output_1)\n",
    "\n",
    "# layer 2\n",
    "output_2 = tf.add(tf.matmul(output_1, weights_2) , biases_2)\n",
    "output_2 = tf.nn.relu(output_2)\n",
    "\n",
    "# output layer\n",
    "output_3 = tf.add(tf.matmul(output_2, weights_3) , biases_3)\n",
    "\n",
    "# dropout\n",
    "output_3_1 = tf.nn.dropout(output_3, keep_prob)\n",
    "\n",
    "# prediction\n",
    "prediction = tf.nn.softmax(output_3)\n",
    "\n",
    "# Cross entropy\n",
    "# cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=output_3_1, labels=labels)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Test Cases\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(loss, feed_dict=train_feed_dict)\n",
    "    session.run(loss, feed_dict=valid_feed_dict)\n",
    "    session.run(loss, feed_dict=test_feed_dict)\n",
    "    biases_data = session.run(biases_1)\n",
    "\n",
    "# assert not np.count_nonzero(biases_data), 'biases must be zeros'\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/200: 100%|██████████| 497/497 [00:00<00:00, 788.50batches/s]\n",
      "Epoch  2/200: 100%|██████████| 497/497 [00:00<00:00, 716.97batches/s]\n",
      "Epoch  3/200: 100%|██████████| 497/497 [00:00<00:00, 895.90batches/s]\n",
      "Epoch  4/200: 100%|██████████| 497/497 [00:00<00:00, 928.40batches/s]\n",
      "Epoch  5/200: 100%|██████████| 497/497 [00:00<00:00, 872.85batches/s]\n",
      "Epoch  6/200: 100%|██████████| 497/497 [00:00<00:00, 840.82batches/s]\n",
      "Epoch  7/200: 100%|██████████| 497/497 [00:00<00:00, 980.91batches/s]\n",
      "Epoch  8/200: 100%|██████████| 497/497 [00:00<00:00, 844.66batches/s]\n",
      "Epoch  9/200: 100%|██████████| 497/497 [00:00<00:00, 801.89batches/s]\n",
      "Epoch 10/200: 100%|██████████| 497/497 [00:00<00:00, 827.23batches/s]\n",
      "Epoch 11/200: 100%|██████████| 497/497 [00:00<00:00, 662.14batches/s]\n",
      "Epoch 12/200: 100%|██████████| 497/497 [00:00<00:00, 831.88batches/s]\n",
      "Epoch 13/200: 100%|██████████| 497/497 [00:00<00:00, 953.70batches/s]\n",
      "Epoch 14/200: 100%|██████████| 497/497 [00:00<00:00, 980.43batches/s]\n",
      "Epoch 15/200: 100%|██████████| 497/497 [00:00<00:00, 1017.19batches/s]\n",
      "Epoch 16/200: 100%|██████████| 497/497 [00:00<00:00, 751.46batches/s]\n",
      "Epoch 17/200: 100%|██████████| 497/497 [00:00<00:00, 924.33batches/s]\n",
      "Epoch 18/200: 100%|██████████| 497/497 [00:00<00:00, 955.19batches/s]\n",
      "Epoch 19/200: 100%|██████████| 497/497 [00:00<00:00, 956.19batches/s]\n",
      "Epoch 20/200: 100%|██████████| 497/497 [00:00<00:00, 940.54batches/s]\n",
      "Epoch 21/200: 100%|██████████| 497/497 [00:00<00:00, 989.55batches/s]\n",
      "Epoch 22/200: 100%|██████████| 497/497 [00:00<00:00, 981.78batches/s]\n",
      "Epoch 23/200: 100%|██████████| 497/497 [00:00<00:00, 1009.67batches/s]\n",
      "Epoch 24/200: 100%|██████████| 497/497 [00:00<00:00, 1009.71batches/s]\n",
      "Epoch 25/200: 100%|██████████| 497/497 [00:00<00:00, 728.48batches/s]\n",
      "Epoch 26/200: 100%|██████████| 497/497 [00:00<00:00, 661.24batches/s]\n",
      "Epoch 27/200: 100%|██████████| 497/497 [00:00<00:00, 813.14batches/s]\n",
      "Epoch 28/200: 100%|██████████| 497/497 [00:00<00:00, 887.34batches/s]\n",
      "Epoch 29/200: 100%|██████████| 497/497 [00:00<00:00, 816.60batches/s]\n",
      "Epoch 30/200: 100%|██████████| 497/497 [00:00<00:00, 923.27batches/s]\n",
      "Epoch 31/200: 100%|██████████| 497/497 [00:00<00:00, 915.42batches/s]\n",
      "Epoch 32/200: 100%|██████████| 497/497 [00:00<00:00, 992.59batches/s]\n",
      "Epoch 33/200: 100%|██████████| 497/497 [00:00<00:00, 834.42batches/s]\n",
      "Epoch 34/200: 100%|██████████| 497/497 [00:00<00:00, 880.39batches/s]\n",
      "Epoch 35/200: 100%|██████████| 497/497 [00:00<00:00, 865.33batches/s]\n",
      "Epoch 36/200: 100%|██████████| 497/497 [00:00<00:00, 794.68batches/s]\n",
      "Epoch 37/200: 100%|██████████| 497/497 [00:00<00:00, 829.06batches/s]\n",
      "Epoch 38/200: 100%|██████████| 497/497 [00:00<00:00, 826.99batches/s]\n",
      "Epoch 39/200: 100%|██████████| 497/497 [00:00<00:00, 795.97batches/s]\n",
      "Epoch 40/200: 100%|██████████| 497/497 [00:00<00:00, 835.63batches/s]\n",
      "Epoch 41/200: 100%|██████████| 497/497 [00:00<00:00, 709.84batches/s]\n",
      "Epoch 42/200: 100%|██████████| 497/497 [00:00<00:00, 876.89batches/s]\n",
      "Epoch 43/200: 100%|██████████| 497/497 [00:00<00:00, 923.08batches/s]\n",
      "Epoch 44/200: 100%|██████████| 497/497 [00:00<00:00, 948.18batches/s]\n",
      "Epoch 45/200: 100%|██████████| 497/497 [00:00<00:00, 862.04batches/s]\n",
      "Epoch 46/200: 100%|██████████| 497/497 [00:00<00:00, 927.48batches/s]\n",
      "Epoch 47/200: 100%|██████████| 497/497 [00:00<00:00, 925.91batches/s]\n",
      "Epoch 48/200: 100%|██████████| 497/497 [00:00<00:00, 945.00batches/s]\n",
      "Epoch 49/200: 100%|██████████| 497/497 [00:00<00:00, 913.35batches/s]\n",
      "Epoch 50/200: 100%|██████████| 497/497 [00:00<00:00, 937.41batches/s]\n",
      "Epoch 51/200: 100%|██████████| 497/497 [00:00<00:00, 930.75batches/s]\n",
      "Epoch 52/200: 100%|██████████| 497/497 [00:00<00:00, 898.27batches/s]\n",
      "Epoch 53/200: 100%|██████████| 497/497 [00:00<00:00, 923.35batches/s]\n",
      "Epoch 54/200: 100%|██████████| 497/497 [00:00<00:00, 931.76batches/s]\n",
      "Epoch 55/200: 100%|██████████| 497/497 [00:00<00:00, 902.96batches/s]\n",
      "Epoch 56/200: 100%|██████████| 497/497 [00:00<00:00, 917.77batches/s]\n",
      "Epoch 57/200: 100%|██████████| 497/497 [00:00<00:00, 957.47batches/s]\n",
      "Epoch 58/200: 100%|██████████| 497/497 [00:00<00:00, 889.87batches/s]\n",
      "Epoch 59/200: 100%|██████████| 497/497 [00:00<00:00, 912.99batches/s]\n",
      "Epoch 60/200: 100%|██████████| 497/497 [00:00<00:00, 912.98batches/s]\n",
      "Epoch 61/200: 100%|██████████| 497/497 [00:00<00:00, 924.78batches/s]\n",
      "Epoch 62/200: 100%|██████████| 497/497 [00:00<00:00, 907.23batches/s]\n",
      "Epoch 63/200: 100%|██████████| 497/497 [00:00<00:00, 894.49batches/s]\n",
      "Epoch 64/200: 100%|██████████| 497/497 [00:00<00:00, 915.19batches/s]\n",
      "Epoch 65/200: 100%|██████████| 497/497 [00:00<00:00, 890.84batches/s]\n",
      "Epoch 66/200: 100%|██████████| 497/497 [00:00<00:00, 907.47batches/s]\n",
      "Epoch 67/200: 100%|██████████| 497/497 [00:00<00:00, 887.03batches/s]\n",
      "Epoch 68/200: 100%|██████████| 497/497 [00:00<00:00, 899.64batches/s]\n",
      "Epoch 69/200: 100%|██████████| 497/497 [00:00<00:00, 883.34batches/s]\n",
      "Epoch 70/200: 100%|██████████| 497/497 [00:00<00:00, 922.98batches/s]\n",
      "Epoch 71/200: 100%|██████████| 497/497 [00:00<00:00, 906.94batches/s]\n",
      "Epoch 72/200: 100%|██████████| 497/497 [00:00<00:00, 883.62batches/s]\n",
      "Epoch 73/200: 100%|██████████| 497/497 [00:00<00:00, 794.80batches/s]\n",
      "Epoch 74/200: 100%|██████████| 497/497 [00:00<00:00, 733.12batches/s]\n",
      "Epoch 75/200: 100%|██████████| 497/497 [00:00<00:00, 777.62batches/s]\n",
      "Epoch 76/200: 100%|██████████| 497/497 [00:00<00:00, 773.33batches/s]\n",
      "Epoch 77/200: 100%|██████████| 497/497 [00:00<00:00, 827.80batches/s]\n",
      "Epoch 78/200: 100%|██████████| 497/497 [00:00<00:00, 810.20batches/s]\n",
      "Epoch 79/200: 100%|██████████| 497/497 [00:00<00:00, 885.60batches/s]\n",
      "Epoch 80/200: 100%|██████████| 497/497 [00:00<00:00, 861.64batches/s]\n",
      "Epoch 81/200: 100%|██████████| 497/497 [00:00<00:00, 887.46batches/s]\n",
      "Epoch 82/200: 100%|██████████| 497/497 [00:00<00:00, 952.57batches/s]\n",
      "Epoch 83/200: 100%|██████████| 497/497 [00:00<00:00, 954.11batches/s]\n",
      "Epoch 84/200: 100%|██████████| 497/497 [00:00<00:00, 911.72batches/s]\n",
      "Epoch 85/200: 100%|██████████| 497/497 [00:00<00:00, 881.21batches/s]\n",
      "Epoch 86/200: 100%|██████████| 497/497 [00:00<00:00, 844.97batches/s]\n",
      "Epoch 87/200: 100%|██████████| 497/497 [00:00<00:00, 792.90batches/s]\n",
      "Epoch 88/200: 100%|██████████| 497/497 [00:00<00:00, 804.98batches/s]\n",
      "Epoch 89/200: 100%|██████████| 497/497 [00:00<00:00, 817.85batches/s]\n",
      "Epoch 90/200: 100%|██████████| 497/497 [00:00<00:00, 875.31batches/s]\n",
      "Epoch 91/200: 100%|██████████| 497/497 [00:00<00:00, 836.10batches/s]\n",
      "Epoch 92/200: 100%|██████████| 497/497 [00:00<00:00, 817.74batches/s]\n",
      "Epoch 93/200: 100%|██████████| 497/497 [00:00<00:00, 694.76batches/s]\n",
      "Epoch 94/200: 100%|██████████| 497/497 [00:00<00:00, 828.89batches/s]\n",
      "Epoch 95/200: 100%|██████████| 497/497 [00:00<00:00, 813.98batches/s]\n",
      "Epoch 96/200: 100%|██████████| 497/497 [00:00<00:00, 829.22batches/s]\n",
      "Epoch 97/200: 100%|██████████| 497/497 [00:00<00:00, 842.05batches/s]\n",
      "Epoch 98/200: 100%|██████████| 497/497 [00:00<00:00, 845.17batches/s]\n",
      "Epoch 99/200: 100%|██████████| 497/497 [00:00<00:00, 853.09batches/s]\n",
      "Epoch 100/200: 100%|██████████| 497/497 [00:00<00:00, 851.91batches/s]\n",
      "Epoch 101/200: 100%|██████████| 497/497 [00:00<00:00, 782.75batches/s]\n",
      "Epoch 102/200: 100%|██████████| 497/497 [00:00<00:00, 827.25batches/s]\n",
      "Epoch 103/200: 100%|██████████| 497/497 [00:00<00:00, 801.12batches/s]\n",
      "Epoch 104/200: 100%|██████████| 497/497 [00:00<00:00, 983.76batches/s]\n",
      "Epoch 105/200: 100%|██████████| 497/497 [00:00<00:00, 895.14batches/s]\n",
      "Epoch 106/200: 100%|██████████| 497/497 [00:00<00:00, 902.20batches/s]\n",
      "Epoch 107/200: 100%|██████████| 497/497 [00:00<00:00, 956.63batches/s]\n",
      "Epoch 108/200: 100%|██████████| 497/497 [00:00<00:00, 998.85batches/s]\n",
      "Epoch 109/200: 100%|██████████| 497/497 [00:00<00:00, 987.01batches/s]\n",
      "Epoch 110/200: 100%|██████████| 497/497 [00:00<00:00, 946.92batches/s]\n",
      "Epoch 111/200: 100%|██████████| 497/497 [00:00<00:00, 921.54batches/s]\n",
      "Epoch 112/200: 100%|██████████| 497/497 [00:00<00:00, 945.23batches/s]\n",
      "Epoch 113/200: 100%|██████████| 497/497 [00:00<00:00, 878.17batches/s]\n",
      "Epoch 114/200: 100%|██████████| 497/497 [00:00<00:00, 967.63batches/s]\n",
      "Epoch 115/200: 100%|██████████| 497/497 [00:00<00:00, 825.16batches/s]\n",
      "Epoch 116/200: 100%|██████████| 497/497 [00:00<00:00, 831.25batches/s]\n",
      "Epoch 117/200: 100%|██████████| 497/497 [00:00<00:00, 902.54batches/s]\n",
      "Epoch 118/200: 100%|██████████| 497/497 [00:00<00:00, 778.77batches/s]\n",
      "Epoch 119/200: 100%|██████████| 497/497 [00:00<00:00, 856.41batches/s]\n",
      "Epoch 120/200: 100%|██████████| 497/497 [00:00<00:00, 861.96batches/s]\n",
      "Epoch 121/200: 100%|██████████| 497/497 [00:00<00:00, 891.32batches/s]\n",
      "Epoch 122/200: 100%|██████████| 497/497 [00:00<00:00, 697.61batches/s]\n",
      "Epoch 123/200: 100%|██████████| 497/497 [00:00<00:00, 847.61batches/s]\n",
      "Epoch 124/200: 100%|██████████| 497/497 [00:00<00:00, 937.56batches/s]\n",
      "Epoch 125/200: 100%|██████████| 497/497 [00:00<00:00, 888.14batches/s]\n",
      "Epoch 126/200: 100%|██████████| 497/497 [00:00<00:00, 945.47batches/s]\n",
      "Epoch 127/200: 100%|██████████| 497/497 [00:00<00:00, 950.55batches/s]\n",
      "Epoch 128/200: 100%|██████████| 497/497 [00:00<00:00, 998.60batches/s]\n",
      "Epoch 129/200: 100%|██████████| 497/497 [00:00<00:00, 1005.13batches/s]\n",
      "Epoch 130/200: 100%|██████████| 497/497 [00:00<00:00, 1016.45batches/s]\n",
      "Epoch 131/200: 100%|██████████| 497/497 [00:00<00:00, 969.04batches/s]\n",
      "Epoch 132/200: 100%|██████████| 497/497 [00:00<00:00, 1000.92batches/s]\n",
      "Epoch 133/200: 100%|██████████| 497/497 [00:00<00:00, 958.94batches/s]\n",
      "Epoch 134/200: 100%|██████████| 497/497 [00:00<00:00, 993.60batches/s]\n",
      "Epoch 135/200: 100%|██████████| 497/497 [00:00<00:00, 576.79batches/s]\n",
      "Epoch 136/200: 100%|██████████| 497/497 [00:00<00:00, 841.08batches/s]\n",
      "Epoch 137/200: 100%|██████████| 497/497 [00:00<00:00, 839.60batches/s]\n",
      "Epoch 138/200: 100%|██████████| 497/497 [00:00<00:00, 1018.56batches/s]\n",
      "Epoch 139/200: 100%|██████████| 497/497 [00:00<00:00, 1010.01batches/s]\n",
      "Epoch 140/200: 100%|██████████| 497/497 [00:00<00:00, 984.85batches/s]\n",
      "Epoch 141/200: 100%|██████████| 497/497 [00:00<00:00, 946.31batches/s]\n",
      "Epoch 142/200: 100%|██████████| 497/497 [00:00<00:00, 840.11batches/s]\n",
      "Epoch 143/200: 100%|██████████| 497/497 [00:00<00:00, 858.35batches/s]\n",
      "Epoch 144/200: 100%|██████████| 497/497 [00:00<00:00, 719.17batches/s]\n",
      "Epoch 145/200: 100%|██████████| 497/497 [00:00<00:00, 683.18batches/s]\n",
      "Epoch 146/200: 100%|██████████| 497/497 [00:00<00:00, 694.77batches/s]\n",
      "Epoch 147/200: 100%|██████████| 497/497 [00:00<00:00, 723.42batches/s]\n",
      "Epoch 148/200: 100%|██████████| 497/497 [00:00<00:00, 722.03batches/s]\n",
      "Epoch 149/200: 100%|██████████| 497/497 [00:00<00:00, 742.11batches/s]\n",
      "Epoch 150/200: 100%|██████████| 497/497 [00:00<00:00, 776.35batches/s]\n",
      "Epoch 151/200: 100%|██████████| 497/497 [00:00<00:00, 777.56batches/s]\n",
      "Epoch 152/200: 100%|██████████| 497/497 [00:00<00:00, 765.42batches/s]\n",
      "Epoch 153/200: 100%|██████████| 497/497 [00:00<00:00, 764.57batches/s]\n",
      "Epoch 154/200: 100%|██████████| 497/497 [00:00<00:00, 763.72batches/s]\n",
      "Epoch 155/200: 100%|██████████| 497/497 [00:00<00:00, 738.42batches/s]\n",
      "Epoch 156/200: 100%|██████████| 497/497 [00:00<00:00, 744.73batches/s]\n",
      "Epoch 157/200: 100%|██████████| 497/497 [00:00<00:00, 739.18batches/s]\n",
      "Epoch 158/200: 100%|██████████| 497/497 [00:00<00:00, 627.05batches/s]\n",
      "Epoch 159/200: 100%|██████████| 497/497 [00:00<00:00, 568.85batches/s]\n",
      "Epoch 160/200: 100%|██████████| 497/497 [00:00<00:00, 603.45batches/s]\n",
      "Epoch 161/200: 100%|██████████| 497/497 [00:00<00:00, 714.79batches/s]\n",
      "Epoch 162/200: 100%|██████████| 497/497 [00:00<00:00, 852.33batches/s]\n",
      "Epoch 163/200: 100%|██████████| 497/497 [00:00<00:00, 923.04batches/s]\n",
      "Epoch 164/200: 100%|██████████| 497/497 [00:00<00:00, 953.60batches/s]\n",
      "Epoch 165/200: 100%|██████████| 497/497 [00:00<00:00, 973.74batches/s]\n",
      "Epoch 166/200: 100%|██████████| 497/497 [00:00<00:00, 949.13batches/s]\n",
      "Epoch 167/200: 100%|██████████| 497/497 [00:00<00:00, 929.04batches/s]\n",
      "Epoch 168/200: 100%|██████████| 497/497 [00:00<00:00, 963.82batches/s]\n",
      "Epoch 169/200: 100%|██████████| 497/497 [00:00<00:00, 952.33batches/s]\n",
      "Epoch 170/200: 100%|██████████| 497/497 [00:00<00:00, 976.88batches/s]\n",
      "Epoch 171/200: 100%|██████████| 497/497 [00:00<00:00, 833.71batches/s]\n",
      "Epoch 172/200: 100%|██████████| 497/497 [00:00<00:00, 843.53batches/s]\n",
      "Epoch 173/200: 100%|██████████| 497/497 [00:00<00:00, 737.55batches/s]\n",
      "Epoch 174/200: 100%|██████████| 497/497 [00:00<00:00, 764.19batches/s]\n",
      "Epoch 175/200: 100%|██████████| 497/497 [00:00<00:00, 708.56batches/s]\n",
      "Epoch 176/200: 100%|██████████| 497/497 [00:00<00:00, 740.34batches/s]\n",
      "Epoch 177/200: 100%|██████████| 497/497 [00:00<00:00, 750.37batches/s]\n",
      "Epoch 178/200: 100%|██████████| 497/497 [00:00<00:00, 788.78batches/s]\n",
      "Epoch 179/200: 100%|██████████| 497/497 [00:00<00:00, 771.57batches/s]\n",
      "Epoch 180/200: 100%|██████████| 497/497 [00:00<00:00, 827.49batches/s]\n",
      "Epoch 181/200: 100%|██████████| 497/497 [00:00<00:00, 763.47batches/s]\n",
      "Epoch 182/200: 100%|██████████| 497/497 [00:00<00:00, 803.43batches/s]\n",
      "Epoch 183/200: 100%|██████████| 497/497 [00:00<00:00, 762.26batches/s]\n",
      "Epoch 184/200: 100%|██████████| 497/497 [00:00<00:00, 712.68batches/s]\n",
      "Epoch 185/200: 100%|██████████| 497/497 [00:00<00:00, 700.97batches/s]\n",
      "Epoch 186/200: 100%|██████████| 497/497 [00:00<00:00, 684.97batches/s]\n",
      "Epoch 187/200: 100%|██████████| 497/497 [00:00<00:00, 593.83batches/s]\n",
      "Epoch 188/200: 100%|██████████| 497/497 [00:00<00:00, 838.76batches/s]\n",
      "Epoch 189/200: 100%|██████████| 497/497 [00:00<00:00, 828.95batches/s]\n",
      "Epoch 190/200: 100%|██████████| 497/497 [00:00<00:00, 987.93batches/s]\n",
      "Epoch 191/200: 100%|██████████| 497/497 [00:00<00:00, 995.32batches/s]\n",
      "Epoch 192/200: 100%|██████████| 497/497 [00:00<00:00, 879.84batches/s]\n",
      "Epoch 193/200: 100%|██████████| 497/497 [00:00<00:00, 752.59batches/s]\n",
      "Epoch 194/200: 100%|██████████| 497/497 [00:00<00:00, 803.68batches/s]\n",
      "Epoch 195/200: 100%|██████████| 497/497 [00:00<00:00, 826.54batches/s]\n",
      "Epoch 196/200: 100%|██████████| 497/497 [00:00<00:00, 772.73batches/s]\n",
      "Epoch 197/200: 100%|██████████| 497/497 [00:00<00:00, 766.51batches/s]\n",
      "Epoch 198/200: 100%|██████████| 497/497 [00:00<00:00, 791.93batches/s]\n",
      "Epoch 199/200: 100%|██████████| 497/497 [00:00<00:00, 762.28batches/s]\n",
      "Epoch 200/200: 100%|██████████| 497/497 [00:00<00:00, 752.50batches/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYF9Wd7/H3hwZEEAVEEWlDE0KiDbL2dcEVF0TjSDQa\nwQXEOIwm5mpMnGDMmGWe50ZnjGNcRuUquEQhuMKTqCiYTMjNRAURZB1Q2tjsiwIiRhq+949f0fy6\n6Z2mf0X35/U8v6erTp2qc+pr01+r6vxOKSIwMzNLmxa57oCZmVllnKDMzCyVnKDMzCyVnKDMzCyV\nnKDMzCyVnKDMzCyVnKDMzCyVnKDM6khSsaRzct0Ps6bOCcrMzFLJCcqsgUj6R0nLJW2SNE3S0Um5\nJP2HpHWStkh6T1KfZNsFkhZJ2ipppaQf5vYszNLDCcqsAUg6C/gl8C2gK/AhMDnZPBQ4HfgqcFhS\nZ2Oy7THgnyKiPdAHeKMRu22Wai1z3QGzJuJKYEJEvAMg6TbgY0kFwA6gPXAs8FZELM7abwdQKGle\nRHwMfNyovTZLMV9BmTWMo8lcNQEQEZ+SuUrqFhFvAA8ADwLrJI2XdGhS9ZvABcCHkv5L0smN3G+z\n1HKCMmsYq4Duu1cktQMOB1YCRMR9ETEIKCRzq+/WpPztiBgOHAm8BExp5H6bpZYTlFn9tJLUZvcH\nmASMkdRf0kHA/wHejIhiSf9L0omSWgHbgM+BXZJaS7pS0mERsQPYAuzK2RmZpYwTlFn9vAxsz/qc\nCfwL8DywGugJjEjqHgr8XzLPlz4kc+vv35NtVwPFkrYA15N5lmVmgPzCQjMzSyNfQZmZWSo5QZmZ\nWSo5QZmZWSo5QZmZWSqlciaJzp07R0FBQa67YWZmlZgzZ86GiDhif7eTygRVUFDA7Nmzc90NMzOr\nhKQPa6617+p8i09SB0nPSVoiabGkkyV1kvS6pGXJz45Z9W9LZnheKum8hu2+mZk1VfV5BvVr4NWI\nOBboBywGxgEzI6IXMDNZR1IhmS8r9gaGAf8pKa+mBgJ/N8vMrLmrU4KSdBiZ1wY8BhARX0TEJ8Bw\n4Imk2hPAN5Ll4cDkiPh7RKwAlgMn1NTOJ59/UpdumZlZE1TXK6gewHpgoqS5kh5NJsXsEhGrkzpr\ngC7Jcjfgo6z9S5KyvUgaK2m2pNlbtmypY7fMzKypqWuCagkMBB6KiAFkJr4cl10hMnMn1fkeXUSM\nj4iiiCg6tP2hNe9gZmZNWl0TVAlQEhFvJuvPkUlYayV1BUh+rku2rwSOydo/PykzMzOrVp0SVESs\nAT6S9LWk6GxgETANGJ2UjQamJsvTgBGSDpLUA+gFvLXPvTYzsyavPt+D+h7wtKTWwAfAGDKJboqk\nb5N5ncC3ACJioaQpZJJYKfDdiNhZUwMexWdmZql83caXe385Plj4Qa67YWZmlZA0JyKK9nc7novP\nzMxSyQnKzMxSyQnKzMxSKZUJyoMkzMwslQnKzMwsnQnKF1BmZs1eKhOUb/GZmVkqE5SZmZkTlJmZ\npZITlJmZpZITlJmZpVIqE5QHSZiZWSoTlJmZmROUmZmlUjoTlO/wmZk1e+lMUGZm1uylMkF5kISZ\nmaUyQZmZmTlBmZlZKjlBmZlZKtUrQUnKkzRX0u+S9U6SXpe0LPnZMavubZKWS1oq6bzaHN/PoMzM\nrL5XUDcBi7PWxwEzI6IXMDNZR1IhMALoDQwD/lNSXv27a2ZmzUWdE5SkfODrwKNZxcOBJ5LlJ4Bv\nZJVPjoi/R8QKYDlwQv27a2ZmzUV9rqDuBf4Z2JVV1iUiVifLa4AuyXI34KOseiVJ2V4kjZU0W9Ls\nbZ9uq0e3zMysKalTgpJ0IbAuIuZUVScignrMBRER4yOiKCKK2rVrV9fdzcysiWlZx/qnABdJugBo\nAxwq6TfAWkldI2K1pK7AuqT+SuCYrP3zk7JqeZCEmZnV6QoqIm6LiPyIKCAz+OGNiLgKmAaMTqqN\nBqYmy9OAEZIOktQD6AW81SA9NzOzJq2uV1BVuROYIunbwIfAtwAiYqGkKcAioBT4bkTsbKA2zcys\nCVPmkVG65B+bHyVLSnLdDTMzq4SkORFRtL/b8UwSZmaWSqlMUB4kYWZmqUxQZmZm6UxQvoAyM2v2\n0pmgzMys2UtlgvIzKDMzS2WCMjMzc4IyM7NUcoIyM7NUcoIyM7NUSmWC8iAJMzNLZYIyMzNzgjIz\ns1RKZ4LyHT4zs2YvlQnKz6DMzCyVCcrMzMwJyszMUskJyszMUskJyszMUqlOCUrSMZL+IGmRpIWS\nbkrKO0l6XdKy5GfHrH1uk7Rc0lJJ59WmHQ+SMDOzul5BlQI/iIhC4CTgu5IKgXHAzIjoBcxM1km2\njQB6A8OA/5SU11CdNzOzpqtOCSoiVkfEO8nyVmAx0A0YDjyRVHsC+EayPByYHBF/j4gVwHLghIbo\nuJmZNW31fgYlqQAYALwJdImI1cmmNUCXZLkb8FHWbiVJWWXHGytptqTZ2z/bXt9umZlZE1GvBCXp\nEOB54OaI2JK9LSKCeswFERHjI6IoIooOPvjg+nTLzMyakDonKEmtyCSnpyPihaR4raSuyfauwLqk\nfCVwTNbu+UlZtTxIwszM6jqKT8BjwOKIuCdr0zRgdLI8GpiaVT5C0kGSegC9gLf2rctmZtYctKxj\n/VOAq4H3JL2blP0YuBOYIunbwIfAtwAiYqGkKcAiMiMAvxsROxuk52Zm1qQp88goXY7sdWSsW7au\n5opmZtboJM2JiKL93U4qZ5LwMygzM0tlgjIzM3OCMjOzVEpngvIdPjOzZi+dCcrMzJq9VCYoD5Iw\nM7NUJigzMzMnKDMzSyUnKDMzSyUnKDMzS6VUJigPkjAzs1QmKDMzMycoMzNLpXQmKN/hMzNr9lKZ\noPwMyszMUpmgzMzMnKDMzCyVnKDMzCyVnKDMzCyVUpmgPEjCzMwaJUFJGiZpqaTlksY1RptmZnZg\n2+8JSlIe8CBwPlAIjJRUuL/bNTOzA1vLRmjjBGB5RHwAIGkyMBxYVNUOmz/fTMG9BY3QtXSTlOsu\nmDVZEZlHCTU9UhD7/u+wpn/LQgRR1qd9PV5lx69Kmh+pNEaC6gZ8lLVeApxYsZKkscBYgHbd2nFm\nwZmN0LX0SvMvjdmBLiKQVPaHu6o/+JUljCDqlLRq+rccEWXHzO5TfY9X2fGrOk5N51/V8YoprlMf\n6qsxElStRMR4YDxAUVFRPP6Nx3PbITMzq9RTPNUo7TTGIImVwDFZ6/lJmZmZWZUaI0G9DfSS1ENS\na2AEMK0R2jUzswPYfr/FFxGlkm4EpgN5wISIWFhV/eRZ1AZJH+7vvh3AOgMbct2JFHN8auYYVc/x\nqd7XGqMR1XbUSGORNDsiinLdjzRzjKrn+NTMMaqe41O9xopPKmeSMDMzc4IyM7NUSmOCGp/rDhwA\nHKPqOT41c4yq5/hUr1Hik7pnUGZmZpDOKygzMzMnKDMzS6dUJajm8loOScdI+oOkRZIWSropKe8k\n6XVJy5KfHbP2uS2Jy1JJ52WVD5L0XrLtPiWTakk6SNJvk/I3JRU09nk2BEl5kuZK+l2y7hglJHWQ\n9JykJZIWSzrZ8SlP0veTf2MLJE2S1KY5x0jSBEnrJC3IKmuUeEganbSxTNLoWnU4IlLxIfMl3veB\nLwOtgXlAYa77tZ/OtSswMFluD/wPmVeR/BswLikfB9yVLBcm8TgI6JHEKS/Z9hZwEiDgFeD8pPw7\nwMPJ8gjgt7k+73rG6hbgGeB3ybpjtCc2TwDXJcutgQ6OT7n4dANWAAcn61OAa5pzjIDTgYHAgqyy\n/R4PoBPwQfKzY7Lcscb+5jpgWUE6GZietX4bcFuu+9VI5z4VOBdYCnRNyroCSyuLBZlZOU5O6izJ\nKh8JPJJdJ1luSeZb8cr1udYxLvnATOAs9iQoxyjT38PI/PFVhXLHZ8+57H6TQqek/78Dhjb3GAEF\nlE9Q+z0e2XWSbY8AI2vqa5pu8VX2Wo5uOepLo0kugQcAbwJdImJ1smkN0CVZrio23ZLliuXl9omI\nUmAzcHiDn8D+dS/wz8CurDLHKKMHsB6YmNwCfVRSOxyfMhGxErgb+BuwGtgcEa/hGFXUGPGo19/3\nNCWoZkfSIcDzwM0RsSV7W2T+N6PZfgdA0oXAuoiYU1WdZh6jlmRu1TwUEQOAbWRuz5Rp5vEheZYy\nnEwyPxpoJ+mq7DrNPUYVpS0eaUpQzeq1HJJakUlOT0fEC0nxWkldk+1dgXVJeVWxWZksVywvt4+k\nlmRuCW1s+DPZb04BLpJUDEwGzpL0Gxyj3UqAkoh4M1l/jkzCcnz2OAdYERHrI2IH8AIwGMeoosaI\nR73+vqcpQTWb13IkI14eAxZHxD1Zm6YBu0e3jCbzbGp3+YhkhEwPoBfwVnJZvkXSSckxR1XYZ/ex\nLgXeSP7v6IAQEbdFRH5EFJD5XXgjIq7CMQIgItYAH0naPav02cAiHJ9sfwNOktQ2ObezgcU4RhU1\nRjymA0MldUyubIcmZdXL9QO7Cg/vLiAzou194PZc92c/nuepZC6j5wPvJp8LyNyrnQksA2YAnbL2\nuT2Jy1KSETNJeRGwINn2AHtmB2kDPAssJzPi5su5Pu99iNeZ7Bkk4RjtOa/+wOzk9+glMqOjHJ/y\nMfo5sCQ5v6fIjEhrtjECJpF5HreDzFX4txsrHsC1SflyYExt+uupjszMLJXSdIvPzMysjBOUmZml\nkhOUmZmlkhOUmZmlkhOUmZmlkhOUmZmlkhOUmZmlkhOUmZmlkhOUmZmlkhOUmZmlkhOUmZmlkhOU\nmZmlkhOUmZmlkhOUNXuS/ijpY0kH5bovZraHE5Q1a5IKgNPIvJ/rokZst2VjtWV2oHKCsuZuFPBX\n4HH2vAkUSQdL+pWkDyVtlvRnSQcn206V9BdJn0j6SNI1SfkfJV2XdYxrJP05az0kfVfSMjIvh0PS\nr5NjbJE0R9JpWfXzJP1Y0vuStibbj5H0oKRfZZ+EpGmSvr8/AmSWK05Q1tyNAp5OPudJ6pKU3w0M\nAgYDnYB/BnZJ6g68AtwPHEHmrbbv1qG9bwAnAoXJ+tvJMToBzwDPSmqTbLsFGEnmbcuHknkj6WfA\nE8BISS0AJHUGzkn2N2synKCs2ZJ0KtAdmBIRc8i8vvqK5A//tcBNEbEyInZGxF8i4u/AFcCMiJgU\nETsiYmNE1CVB/TIiNkXEdoCI+E1yjNKI+BWZV5J/Lal7HfCTiFgaGfOSum8Bm4Gzk3ojgD9GxNp9\nDIlZqjhBWXM2GngtIjYk688kZZ2BNmQSVkXHVFFeWx9lr0j6oaTFyW3ET4DDkvZrausJ4Kpk+Srg\nqX3ok1kq+UGtNUvJ86RvAXmS1iTFBwEdgK7A50BPYF6FXT8CTqjisNuAtlnrR1VSJ7L6cBqZW4dn\nAwsjYpekjwFltdUTWFDJcX4DLJDUDzgOeKmKPpkdsHwFZc3VN4CdZJ4F9U8+xwGzyDyXmgDcI+no\nZLDCyckw9KeBcyR9S1JLSYdL6p8c813gEkltJX0F+HYNfWgPlALrgZaS7iDzrGm3R4F/ldRLGX0l\nHQ4QESVknl89BTy/+5ahWVPiBGXN1WhgYkT8LSLW7P4ADwBXAuOA98gkgU3AXUCLiPgbmUELP0jK\n3wX6Jcf8D+ALYC2ZW3BP19CH6cCrwP8AH5K5asu+BXgPMAV4DdgCPAYcnLX9CeB4fHvPmihFRM21\nzCx1JJ1O5lZf9/A/ZGuCfAVldgCS1Aq4CXjUycmaqhoTlKQJktZJquxBLcm98fskLZc0X9LArG3D\nJC1Nto1ryI6bNVeSjgM+ITOY494cd8dsv6nNFdTjwLBqtp8P9Eo+Y4GHIPMteODBZHshmS8WFlZ1\nEDOrnYhYHBHtImJwRGzJdX/M9pcaE1RE/InMw+CqDAeeTL5I+Fegg6SuZIbiLo+IDyLiC2ByUtfM\nzKxGDfE9qG6UH3lUkpRVVn5iVQeRNJbMFRjt2rUbdOyxxzZA18zMrKHNmTNnQ0Qcsb/bSc0XdSNi\nPDAeoKioKGbPnp3jHpmZWWUkfdgY7TREglpJZkqW3fKTslZVlJuZmdWoIYaZTwNGJaP5TgI2R8Rq\nMl9w7CWph6TWZCa0nNYA7ZmZWTNQ4xWUpEnAmUBnSSXAT8lcHRERDwMvk/lm/XIyrwIYk2wrlXQj\nmW/L5wETImLhfjgHMzNrgmpMUBExsobtAXy3im0vk0lgZmZmdZKaQRLZlqzZysB/fY2t20vZsSvK\npnaGzFTQNa2zu0yw+zv2dT2G20jXMd1G0+93U2njQO13bdpo2QIObdOKVkcUHE8jSGWC2rFzF5u2\n7ShbrziPS03rZWVRdZ19XXcbjXtMt5HbY7qN3B4zLW2U7oJNn+1AeS1bV1K9waUyQRHsSdlmZtYs\npTNBCZBqrGZmZk2XZzM3M7NUcoIyM7NUSuUtvlZ5LejUrpVH8R2gbRyo/W4qbRyo/W4qbRyo/a7L\nKL5VO0u/oBGk8o26novPzCy9JM2JiKL93Y5v8ZmZWSo5QZmZWSo5QZmZWSo5QZmZWSo5QZmZWSo5\nQZmZWSo5QZmZWSrVKkFJGiZpqaTlksZVsv1WSe8mnwWSdkrqlGwrlvRess1fbjIzs1qpzRt184AH\ngXOBEuBtSdMiYtHuOhHx78C/J/X/Afh+RGzKOsyQiNjQoD03M7MmrTZXUCcAyyPig4j4ApgMDK+m\n/khgUkN0zszMmq/aJKhuwEdZ6yVJ2V4ktQWGAc9nFQcwQ9IcSWOrakTSWEmzJc1ev359LbplZmZN\nWUMPkvgH4P9VuL13akT0B84Hvivp9Mp2jIjxEVEUEUVHHHFEA3fLzMwONLVJUCuBY7LW85Oyyoyg\nwu29iFiZ/FwHvEjmlqGZmVm1apOg3gZ6SeohqTWZJDStYiVJhwFnAFOzytpJar97GRgKLGiIjpuZ\nWdNW4yi+iCiVdCMwHcgDJkTEQknXJ9sfTqpeDLwWEduydu8CvKjM69tbAs9ExKsNeQJmZtY0+X1Q\nZmZWJ34flJmZNWtOUGZmlkpOUGZmlkpOUGZmlkpOUGZmlkpOUGZmlkpOUGZmlkpOUGZmlkpOUGZm\nlkpOUGZmlkpOUGZmlkpOUGZmlkpOUGZmlkpOUGZmlkq1SlCShklaKmm5pHGVbD9T0mZJ7yafO2q7\nr5mZWWVqfGGhpDzgQeBcoAR4W9K0iFhUoeqsiLiwnvuamZmVU5srqBOA5RHxQUR8AUwGhtfy+Puy\nr5mZNWO1SVDdgI+y1kuSsooGS5ov6RVJveu4L5LGSpotafb69etr0S0zM2vKGmqQxDvAlyKiL3A/\n8FJdDxAR4yOiKCKKjjjiiAbqlpmZHahqk6BWAsdkrecnZWUiYktEfJosvwy0ktS5NvuamZlVpjYJ\n6m2gl6QekloDI4Bp2RUkHSVJyfIJyXE31mZfMzOzytQ4ii8iSiXdCEwH8oAJEbFQ0vXJ9oeBS4Eb\nJJUC24ERERFApfvup3MxM7MmRJk8ki5FRUUxe/bsXHfDzMwqIWlORBTt73Y8k4SZmaWSE5SZmaWS\nE5SZmaWSE5SZmaVSjaP4zKzp27FjByUlJXz++ee57oqlSJs2bcjPz6dVq1Y5ad8JyswoKSmhffv2\nFBQUkHyl0Zq5iGDjxo2UlJTQo0ePnPTBt/jMjM8//5zDDz/cycnKSOLwww/P6VW1E5SZATg52V5y\n/TvhBGVmZqnkBGVmObdx40b69+9P//79Oeqoo+jWrVvZ+hdffFGrY4wZM4alS5dWW+fBBx/k6aef\nboguA7B27VpatmzJo48+2mDHtD081ZGZsXjxYo477rhcdwOAn/3sZxxyyCH88Ic/LFceEUQELVqk\n5/+r77//fqZMmULr1q2ZOXPmfmuntLSUli1zM6atst+NxprqyKP4zKy8m2+Gd99t2GP27w/33lvn\n3ZYvX85FF13EgAEDmDt3Lq+//jo///nPeeedd9i+fTuXX345d9xxBwCnnnoqDzzwAH369KFz585c\nf/31vPLKK7Rt25apU6dy5JFH8pOf/ITOnTtz8803c+qpp3LqqafyxhtvsHnzZiZOnMjgwYPZtm0b\no0aNYvHixRQWFlJcXMyjjz5K//799+rfpEmTuP/++7n00ktZvXo1Xbt2BeD3v/89//Iv/8LOnTvp\n0qULr732Glu3buXGG29k7ty5APziF7/gwgsvpHPnznzyyScATJ48mRkzZvDoo49y1VVX0b59e+bM\nmcOZZ57JJZdcwve//30+//xz2rZty+OPP06vXr0oLS3l1ltv5fXXX6dFixZcf/31fOUrX2H8+PE8\n99xzALzyyitMmDCBZ599tl7/+XLFCcrMUm3JkiU8+eSTFBVl/of9zjvvpFOnTpSWljJkyBAuvfRS\nCgsLy+2zefNmzjjjDO68805uueUWJkyYwLhx4/Y6dkTw1ltvMW3aNH7xi1/w6quvcv/993PUUUfx\n/PPPM2/ePAYOHFhpv4qLi9m0aRODBg3isssuY8qUKdx0002sWbOGG264gVmzZtG9e3c2bdoEZK4M\njzjiCObPn09ElCWl6qxevZq//vWvtGjRgs2bNzNr1ixatmzJq6++yk9+8hN++9vf8tBDD7Fq1Srm\nzZtHXl4emzZtokOHDtx4441s3LiRww8/nIkTJ3LttdfWNfQ55wRlZuXV40pnf+rZs2dZcoLMVctj\njz1GaWkpq1atYtGiRXslqIMPPpjzzz8fgEGDBjFr1qxKj33JJZeU1SkuLgbgz3/+Mz/60Y8A6Nev\nH717965038mTJ3P55ZcDMGLECL7zne9w00038d///d8MGTKE7t27A9CpUycAZsyYwUsvZV42LomO\nHTtSWlpa7blfdtllZbc0P/nkE0aNGsX7779frs6MGTO4+eabycvLK9felVdeyTPPPMOVV17JnDlz\nmDRpUrVtpZETlJmlWrt27cqWly1bxq9//WveeustOnTowFVXXVXp93Rat25dtpyXl1dlIjjooINq\nrFOVSZMmsWHDBp544gkAVq1axQcffFCnY7Ro0YLscQAVzyX73G+//XbOO+88vvOd77B8+XKGDRtW\n7bGvvfZavvnNbwJw+eWXlyWwA0mtnjZKGiZpqaTlkva6TpZ0paT5kt6T9BdJ/bK2FSfl70ryyAcz\nq7ctW7bQvn17Dj30UFavXs306dMbvI1TTjmFKVOmAPDee++xaNGiveosWrSI0tJSVq5cSXFxMcXF\nxdx6661MnjyZwYMH84c//IEPP/wQoOwW37nnnsuDDz4IZG4tfvzxx7Ro0YKOHTuybNkydu3axYsv\nvlhlvzZv3ky3bt0AePzxx8vKzz33XB5++GF27txZrr1jjjmGzp07c+edd3LNNdfsW1BypMYEJSkP\neBA4HygERkoqrFBtBXBGRBwP/CswvsL2IRHRvzFGfZhZ0zVw4EAKCws59thjGTVqFKecckqDt/G9\n732PlStXUlhYyM9//nMKCws57LDDytWZNGkSF198cbmyb37zm0yaNIkuXbrw0EMPMXz4cPr168eV\nV14JwE9/+lPWrl1Lnz596N+/f9ltx7vuuovzzjuPwYMHk5+fX2W/fvSjH3HrrbcycODAcldd//RP\n/8RRRx1F37596devX1lyBbjiiivo0aMHX/3qV/c5LrlQ4zBzSScDP4uI85L12wAi4pdV1O8ILIiI\nbsl6MVAUERtq2ykPMzdrXGkaZp5rpaWllJaW0qZNG5YtW8bQoUNZtmxZzoZ574vrr7+ek08+mdGj\nR9f7GGkfZt4N+ChrvQQ4sZr63wZeyVoPYIakncAjEVHx6goASWOBsQBf+tKXatEtM7OG9+mnn3L2\n2WdTWlpKRPDII48ckMmpf//+dOzYkfvuuy/XXam3Bo26pCFkEtSpWcWnRsRKSUcCr0taEhF/qrhv\nkrjGQ+YKqiH7ZWZWWx06dGDOnDm57sY+e7ehv8uWA7UZJLESOCZrPT8pK0dSX+BRYHhEbNxdHhEr\nk5/rgBeBE/alw2Zm1jzUJkG9DfSS1ENSa2AEMC27gqQvAS8AV0fE/2SVt5PUfvcyMBRY0FCdNzOz\npqvGW3wRUSrpRmA6kAdMiIiFkq5Ptj8M3AEcDvxnMj17afIArQvwYlLWEngmIl7dL2diZmZNSq2e\nQUXEy8DLFcoezlq+Driukv0+APpVLDczM6tJeqYFNrMDwsP/9T5/eb/8t0b+8v4GHv6v96vYo2ZD\nhgzZ60u39957LzfccEO1+x1yyCFAZhaHSy+9tNI6Z555JjV9beXee+/ls88+K1u/4IILajVXXm31\n79+fESNGNNjxmgsnKDOrk775h3HjM3PLktRf3t/Ajc/MpW/+YTXsWbWRI0cyefLkcmWTJ09m5MiR\ntdr/6KOPLpu5uz4qJqiXX36ZDh061Pt42RYvXszOnTuZNWsW27Zta5BjVqauUzUdCJygzKxOBvfs\nzANXDODGZ+Zyz2tLufGZuTxwxQAG9+xc72Neeuml/P73vy97OWFxcTGrVq3itNNOK/te0sCBAzn+\n+OOZOnXqXvsXFxfTp08fALZv386IESM47rjjuPjii9m+fXtZvRtuuIGioiJ69+7NT3/6UwDuu+8+\nVq1axZAhQxgyZAgABQUFbNiQScD33HMPffr0oU+fPtybTKRbXFzMcccdxz/+4z/Su3dvhg4dWq6d\nbJMmTeLqq69m6NCh5fq+fPlyzjnnHPr168fAgQPLJoG96667OP744+nXr1/ZDOzZV4EbNmygoKAA\nyEx5dNFFF3HWWWdx9tlnVxurJ598smy2iauvvpqtW7fSo0cPduzYAWSmkcpeT4XdLwFL02fQoEFh\nZo1n0aJFdd7nV9OXRPcf/S5+NX1Jg/Th61//erz00ksREfHLX/4yfvCDH0RExI4dO2Lz5s0REbF+\n/fro2bNn7Nq1KyIi2rVrFxERK1asiN69e2f69atfxZgxYyIiYt68eZGXlxdvv/12RERs3LgxIiJK\nS0vjjDPOiHnz5kVERPfu3WP9+vVlfdm9Pnv27OjTp098+umnsXXr1igsLIx33nknVqxYEXl5eTF3\n7tyIiLjgwQysAAAJbklEQVTsssviqaeeqvS8vvrVr8aHH34Y06dPjwsvvLCs/IQTTogXXnghIiK2\nb98e27Zti5dffjlOPvnk2LZtW7n+nnHGGWXnsH79+ujevXtEREycODG6detWVq+qWC1YsCB69epV\ndo67619zzTXx4osvRkTEI488Erfccste/a/sdwOYHY2QC3wFZWZ19pf3N/CbN//G/z7rK/zmzb/t\n9UyqPrJv82Xf3osIfvzjH9O3b1/OOeccVq5cydq1a6s8zp/+9CeuuuoqAPr27Uvfvn3Ltk2ZMoWB\nAwcyYMAAFi5cWOlEsNn+/Oc/c/HFF9OuXTsOOeQQLrnkkrI59Hr06FH2EsPs13Vkmz17Np07d+ZL\nX/oSZ599NnPnzmXTpk1s3bqVlStXls3n16ZNG9q2bcuMGTMYM2YMbdu2Bfa8OqM65557blm9qmL1\nxhtvcNlll9G5c+dyx73uuuuYOHEiABMnTmTMmDE1tteYnKDMrE52P3N64IoB3DL0a2W3+/Y1SQ0f\nPpyZM2fyzjvv8NlnnzFo0CAAnn76adavX8+cOXN499136dKlS6Wv2KjJihUruPvuu5k5cybz58/n\n61//er2Os9vuV3VA1a/rmDRpEkuWLKGgoICePXuyZcsWnn/++Tq31bJlS3bt2gVU/0qOusbqlFNO\nobi4mD/+8Y/s3Lmz7DZpWjhBmVmdzC/ZXO6Z0+5nUvNLNu/TcQ855BCGDBnCtddeW25wxObNmzny\nyCNp1apVuddYVOX000/nmWeeAWDBggXMnz8fyDxjadeuHYcddhhr167llVf2TBnavn17tm7dutex\nTjvtNF566SU+++wztm3bxosvvshpp51Wq/PZtWsXU6ZM4b333it7JcfUqVOZNGkS7du3Jz8/v+wF\nhn//+9/57LPPOPfcc5k4cWLZgI3dr84oKCgom36pusEgVcXqrLPO4tlnn2Xjxo3ljgswatQorrji\nitRdPYETlJnV0fVn9NxrQMTgnp25/oye+3zskSNHMm/evHIJ6sorr2T27Nkcf/zxPPnkkxx77LHV\nHuOGG27g008/5bjjjuOOO+4ouxLr168fAwYM4Nhjj+WKK64o96qOsWPHMmzYsLJBErsNHDiQa665\nhhNOOIETTzyR6667jgEDBtTqXGbNmkW3bt04+uijy8pOP/10Fi1axOrVq3nqqae477776Nu3L4MH\nD2bNmjUMGzaMiy66iKKiIvr378/dd98NwA9/+EMeeughBgwYUDZ4ozJVxap3797cfvvtnHHGGfTr\n149bbrml3D4ff/xxrUdMNqYaX7eRC37dhlnj8us2mq/nnnuOqVOn8tRTT1W6Pe2v2zAzsyboe9/7\nHq+88govv/xyzZVzwAnKzKyZuv/++3PdhWr5GZSZAZDG2/2WW7n+nXCCMjPatGnDxo0bc/4HydIj\nIti4cSNt2rTJWR98i8/MyM/Pp6SkhPXr1+e6K5Yibdq0IT8/P2ftO0GZGa1ataJHjx657oZZObW6\nxSdpmKSlkpZLGlfJdkm6L9k+X9LA2u5rZmZWmRoTlKQ84EHgfKAQGCmpsEK184FeyWcs8FAd9jUz\nM9tLba6gTgCWR8QHEfEFMBkYXqHOcODJZKLbvwIdJHWt5b5mZmZ7qc0zqG7AR1nrJcCJtajTrZb7\nAiBpLJmrr87Ap5KW1qJvzVVnYN+nj266HJ+aOUbVc3yq97XGaCQ1gyQiYjwwXtLsiCjIdX/SLInR\nfp9m5EDl+NTMMaqe41M9SY0yF11tEtRK4Jis9fykrDZ1WtViXzMzs73U5hnU20AvST0ktQZGANMq\n1JkGjEpG850EbI6I1bXc18zMbC81XkFFRKmkG4HpQB4wISIWSro+2f4w8DJwAbAc+AwYU92+NTQ5\nvr4n04w4RtVzfGrmGFXP8aleo8Qnla/bMDMz81x8ZmaWSk5QZmaWSqlKUM1lWiRJx0j6g6RFkhZK\nuikp7yTpdUnLkp8ds/a5LYnLUknnZZUPkvResu0+SUrKD5L026T8TUkFjX2eDUFSnqS5kn6XrDtG\nCUkdJD0naYmkxZJOdnzKk/T95N/YAkmTJLVpzjGSNEHSOkkLssoaJR6SRidtLJM0ulYdjohUfMgM\nongf+DLQGpgHFOa6X/vpXLsCA5Pl9sD/kJkK6t+AcUn5OOCuZLkwicdBQI8kTnnJtreAkwABrwDn\nJ+XfAR5OlkcAv831edczVrcAzwC/S9Ydoz2xeQK4LlluDXRwfMrFpxuwAjg4WZ8CXNOcYwScDgwE\nFmSV7fd4AJ2AD5KfHZPljjX2N9cBywrSycD0rPXbgNty3a9GOvepwLnAUqBrUtYVWFpZLMiMijw5\nqbMkq3wk8Eh2nWS5JZlvxSvX51rHuOQDM4Gz2JOgHKNMfw8j88dXFcodnz3nsnsmm05J/38HDG3u\nMQIKKJ+g9ns8susk2x4BRtbU1zTd4qtquqQmLbkEHgC8CXSJzPfHANYAXZLl6qaSKqmkvNw+EVEK\nbAYOb/AT2L/uBf4Z2JVV5hhl9ADWAxOTW6CPSmqH41MmIlYCdwN/A1aT+X7mazhGFTVGPOr19z1N\nCarZkXQI8Dxwc0Rsyd4Wmf/NaLbfAZB0IbAuIuZUVaeZx6glmVs1D0XEAGAbmdszZZp5fEiepQwn\nk8yPBtpJuiq7TnOPUUVpi0eaElRtplRqMiS1IpOcno6IF5LitcrMAk/yc11SXlVsVibLFcvL7SOp\nJZlbQhsb/kz2m1OAiyQVk5kF/yxJv8Ex2q0EKImIN5P158gkLMdnj3OAFRGxPiJ2AC8Ag3GMKmqM\neNTr73uaElSzmRYpGfHyGLA4Iu7J2jQN2D26ZTSZZ1O7y0ckI2R6kHnv1lvJZfkWSSclxxxVYZ/d\nx7oUeCP5v6MDQkTcFhH5kZk4eASZ/l+FYwRARKwBPpK0e1bps4FFOD7Z/gacJKltcm5nA4txjCpq\njHhMB4ZK6phc2Q5NyqqX6wd2FR7eXUBmRNv7wO257s9+PM9TyVxGzwfeTT4XkLlXOxNYBswAOmXt\nc3sSl6UkI2aS8iJgQbLtAfbMDtIGeJbM9FNvAV/O9XnvQ7zOZM8gCcdoz3n1B2Ynv0cvkRkd5fiU\nj9HPgSXJ+T1FZkRas40RMInM87gdZK7Cv91Y8QCuTcqXA2Nq019PdWRmZqmUplt8ZmZmZZygzMws\nlZygzMwslZygzMwslZygzMwslZygzMwslZygzMwslf4/w8WG3GbOAQgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fa27978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.9048571586608887\n"
     ]
    }
   ],
   "source": [
    "# Change if you have memory restrictions\n",
    "batch_size = 128\n",
    "\n",
    "# TODO: Find the best parameters for each configuration\n",
    "epochs = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "# optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss) < not working...\n",
    "\n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 100\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "# Save check points\n",
    "save_file = './favorr_05.ckpt'\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels, keep_prob:0.75})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "    \n",
    "    # Save the model\n",
    "    saver.save(session, save_file)\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test?\n",
    "\n",
    "# ### DON'T MODIFY ANYTHING BELOW ###\n",
    "# # The accuracy measured against the test set\n",
    "# test_accuracy = 0.0\n",
    "\n",
    "# with tf.Session() as session:\n",
    "    \n",
    "#     session.run(init)\n",
    "#     batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "#     for epoch_i in range(epochs):\n",
    "        \n",
    "#         # Progress bar\n",
    "#         batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "#         # The training cycle\n",
    "#         for batch_i in batches_pbar:\n",
    "#             # Get a batch of training features and labels\n",
    "#             batch_start = batch_i*batch_size\n",
    "#             batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "#             batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "#             # Run optimizer\n",
    "#             _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels, keep_prob:1.0})\n",
    "\n",
    "#         # Check accuracy against Test data\n",
    "#         test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "\n",
    "# assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greater than 0.80'.format(test_accuracy)\n",
    "# print('Nice Job! Test Accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          5.40000000e+01,   1.96505500e+06],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   6.96980000e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.05100000e+03,   8.00594000e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.45478300e+06],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          5.57000000e+02,   1.63726600e+06]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
